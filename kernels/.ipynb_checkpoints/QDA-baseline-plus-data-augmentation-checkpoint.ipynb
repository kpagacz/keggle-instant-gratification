{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "import numpy as np\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../input/train.csv\", index_col=0)\n",
    "test = pd.read_csv(\"../input/test.csv\", index_col=0)\n",
    "submission = pd.read_csv(\"../input/sample_submission.csv\", index_col=0)\n",
    "\n",
    "category = \"wheezy-copper-turtle-magic\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 512/512 [01:20<00:00,  6.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9647742563613684\n"
     ]
    }
   ],
   "source": [
    "################\n",
    "# QDA\n",
    "################\n",
    "# Config\n",
    "features = [column for column in train.columns if column not in [\"id\", \"target\", category]]\n",
    "probabilities = pd.Series(np.zeros(len(train)), index=train.index)\n",
    "test_predictions = pd.Series(np.zeros(len(test)), index=test.index)\n",
    "\n",
    "# Loop through wheezy-copper-turtle-magic\n",
    "for i in tqdm(range(512)):\n",
    "    # Subset train and test\n",
    "    # where wheezy == i and features only\n",
    "    train_ = train.loc[train[category] == i, :]\n",
    "    test_ = test.loc[test[category] == i, :]\n",
    "    \n",
    "    # VarianceThreshold\n",
    "    from sklearn.feature_selection import VarianceThreshold\n",
    "    feature_selector = VarianceThreshold(threshold = 1.5).fit(train_.loc[:, features])\n",
    "    train_2 = feature_selector.transform(train_.loc[:, features])\n",
    "    test_2 = feature_selector.transform(test_.loc[:, features])\n",
    "    \n",
    "    # At this moment train_ and test_ contain all columns and only samples from wheezy == i\n",
    "    # and train_2 and test_2 contain only selected columns and samples from wheezy == i    \n",
    "    \n",
    "    # Stratified k-fold\n",
    "    skf = sk.model_selection.StratifiedKFold(n_splits=10, random_state=26, shuffle=True)\n",
    "    \n",
    "    for split_train_index, split_test_index in skf.split(train_2, train_[\"target\"]):\n",
    "        # QDA\n",
    "        qda = QuadraticDiscriminantAnalysis()\n",
    "        qda.fit(train_2[split_train_index, :], train_[\"target\"][split_train_index])\n",
    "        \n",
    "        # Getting probabilities of the test part of the split\n",
    "        split_probabilities = qda.predict_proba(train_2[split_test_index, :])[:, 1]\n",
    "        # Saving predictions\n",
    "        probabilities[train_.index[split_test_index]] += split_probabilities\n",
    "        test_predictions[test_.index] += qda.predict_proba(test_2)[:, 1] / skf.n_splits\n",
    "\n",
    "print(sk.metrics.roc_auc_score(train[\"target\"], probabilities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# Data augmentation\n",
    "###################\n",
    "# Psuedo-labeling\n",
    "mask = test_predictions[np.logical_or(test_predictions <= test_predictions.quantile(0.25),\n",
    "                                     test_predictions >= test_predictions.quantile(0.75))].index\n",
    "train_only_psuedo = test.loc[mask, :]\n",
    "train_only_psuedo = train_only_psuedo.assign(target=[1 if el > 0.5 else 0 for el in test_predictions[mask]])\n",
    "\n",
    "# Check if indices match and columns match\n",
    "assert all(test_predictions[mask].index == train_only_psuedo.index)\n",
    "assert all(train.columns == train_only_psuedo.columns)\n",
    "\n",
    "# Concatenate psudeo train with train\n",
    "train_with_psuedo = pd.concat([train, train_only_psuedo])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The idea here is motivated by others and is inspired\n",
    "# by the nature of the dataset\n",
    "# Since we know make_classification with y_flip introduces flips\n",
    "# Let's reverse them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['muggy-smalt-axolotl-pembus', 'dorky-peach-sheepdog-ordinal',\n",
      "       'slimy-seashell-cassowary-goose',\n",
      "       'snazzy-harlequin-chicken-distraction', 'frumpy-smalt-mau-ordinal',\n",
      "       'stealthy-beige-pinscher-golden', 'chummy-cream-tarantula-entropy',\n",
      "       'hazy-emerald-cuttlefish-unsorted', 'nerdy-indigo-wolfhound-sorted',\n",
      "       'leaky-amaranth-lizard-sorted',\n",
      "       ...\n",
      "       'wheezy-myrtle-mandrill-entropy', 'wiggy-lilac-lemming-sorted',\n",
      "       'gloppy-cerise-snail-contributor', 'woozy-silver-havanese-gaussian',\n",
      "       'jumpy-thistle-discus-sorted', 'muggy-turquoise-donkey-important',\n",
      "       'blurry-buff-hyena-entropy', 'bluesy-chocolate-kudu-fepid',\n",
      "       'gamy-white-monster-expert', 'target'],\n",
      "      dtype='object', length=257)\n"
     ]
    }
   ],
   "source": [
    "print(train_with_psuedo.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
